
    <div class="markdown-content" style="font-family: Arial, sans-serif; line-height: 1.6; color: #333; max-width: 800px; margin: 0 auto;">
        <h1>8.8</h1>

<h1>Connecting Sensors to Actions</h1>

<h2>Learning Objectives</h2><p>By the end of this session, you'll be able to:</p>
<ul>
<li>Explain how sensors help robots "see" and "feel" the world</li>
</ul>
<ul>
<li>Show how robots use input-process-output steps to work</li>
</ul>
<ul>
<li>Give examples of how robots make choices based on what they sense</li>
</ul>
<h2>Lesson Podcast Discussion: How Sensors Enable Robot Autonomy</h2><p>This podcast explores how programming robots to interpret sensor data transforms them from simple pre-programmed machines into autonomous systems capable of reacting to their environment.</p>
<h2>Sensor Inputs in Programming</h2><p>When we program robots, we need a way to incorporate information from the physical world. Sensors serve as the robot's senses, allowing it to perceive its environment. In programming terms, sensors provide the input data that the robot can use to make decisions.</p>
<p>&nbsp;</p>

<p>Think about how you use your own senses. When you touch something hot, your brain processes that information and tells your hand to pull away. Robots work in a similar way! A touch sensor can detect pressure, and the robot's program can tell its motors to move away from that pressure.</p>
<p>&nbsp;</p>

<p>Sensors come in many types - light sensors detect brightness, distance sensors measure how far away objects are, and sound sensors can hear noises. Each type gives the robot different information about the world around it.</p>
<h3>The Input-Processing-Output Framework</h3><p>The input-processing-output (IPO) framework is fundamental to understanding how sensors work in robotics:</p>
<ul>
<li><strong>Input</strong>: Sensor data (light levels, distance measurements, touch detection, etc.)</li>
</ul>
<ul>
<li><strong>Processing</strong>: Code that interprets sensor readings and makes decisions</li>
</ul>
<ul>
<li><strong>Output</strong>: Actions the robot takes (motors moving, lights turning on, sounds playing)</li>
</ul>
<p>&nbsp;</p>

<p>This framework helps us think systematically about how to connect sensor readings to robot behaviors. For example, an autonomous vacuum robot uses:</p>
<ul>
<li><strong>Input</strong>: Proximity sensors detect walls and obstacles</li>
</ul>
<ul>
<li><strong>Processing</strong>: Code interprets these readings to determine when to change direction</li>
</ul>
<ul>
<li><strong>Output</strong>: Motor controllers adjust wheel speeds to turn or stop</li>
</ul>
<p>&nbsp;</p>

<p>Let's look at another example: a robot that follows a line on the floor. The robot uses light sensors pointed at the ground to detect the difference between the dark line and the lighter floor. When the sensor detects the line, the robot's program processes this information and sends commands to the motors to adjust the robot's path and stay on the line. This simple input-processing-output cycle happens continuously, allowing the robot to follow the line even when it curves or changes direction.</p>
<p>&nbsp;</p>

<p>In your kitchen, temperature sensors in appliances work the same way. Your refrigerator uses temperature sensors to detect when it's getting too warm inside. The program processes this information and turns on the cooling system to keep your food fresh. When the temperature is low enough, the sensor detects this change, and the program turns the cooling system off again.</p>
<h1>Creating Sensor Response Programs</h1><p>The essence of sensor-based programming is creating conditional responses to sensor inputs. This is typically done using if-then structures and comparison operators.</p>
<p>&nbsp;</p>

<p>When we program robots to respond to sensors, we're essentially creating a set of rules for the robot to follow. These rules usually take the form of "if this happens, then do that." For example, "if the distance sensor detects an object less than 10 centimeters away, then stop moving forward and turn right."</p>
<p>&nbsp;</p>

<p>In programming, we use conditional statements to create these rules. The most common type is the if-else statement, which allows the robot to choose between different actions based on sensor readings.</p>
<h3>Basic Sensor Response Pattern</h3>

<pre><code style="background-color:#f6f8fa; padding:2px 4px; border-radius:3px;">if (sensor_reading &gt; threshold) {
    perform_action_A();
} else {
    perform_action_B();
}
</code></pre>
<p>&nbsp;</p>

<p>This pattern can be expanded to handle multiple conditions or sensor types. For example, a line-following robot might use:</p>
<pre><code style="background-color:#f6f8fa; padding:2px 4px; border-radius:3px;">if (left_light_sensor &lt; dark_threshold &amp;&amp; right_light_sensor &gt; dark_threshold) {
    turn_right();
} else if (left_light_sensor &gt; dark_threshold &amp;&amp; right_light_sensor &lt; dark_threshold) {
    turn_left();
} else if (both_sensors &lt; dark_threshold) {
    move_forward();
} else {
    stop_and_search();
}
</code></pre>
<p>&nbsp;</p>

<p>
            <div class="stop-reflect-container" style="border:3px dashed #e50200; margin:20px 0; padding:0; display:flex; width:100%;">
                <div class="stop-reflect-image" style="width:20%; min-width:100px; display:flex; align-items:center; justify-content:center; padding:10px;">
                    <img src="https://api.learnstage.com/media-manager/api/access/exceled/default/lms/courses/1647/Images/Untitled%20design.jpg" 
                         style="width:100%; height:auto; max-width:150px;" alt="Stop and Reflect">
                </div>
                <div class="stop-reflect-content" style="display:flex; flex-direction:column; justify-content:center; padding:15px; width:80%;">
                    <h3 style="color:#000000; margin-top:0;">
                    </h3><p> Think about the devices you use every day. Can you identify an example of a sensor-based system in your home, school, or a toy that uses the input-processing-output framework we just discussed? How does it detect information and respond to changes?</p>
                </div>
            </div></p>
<h3>Continuous vs. Threshold-Based Responses</h3><p>Robots can respond to sensors in two primary ways:</p>
<ol>
<li><strong>Threshold-based</strong>: Taking different actions based on whether sensor readings cross specific values</li>
</ol>
<ol>
<li><strong>Continuous</strong>: Adjusting actions proportionally to sensor readings (like slowing down as an obstacle gets closer)</li>
</ol>
<p>&nbsp;</p>

<p>Threshold-based responses are like on-off switches. For example, if a light sensor reading goes above 50, turn on a light; otherwise, keep it off. This is simple to program and works well for many situations.</p>
<p>&nbsp;</p>

<p>Continuous responses are more like a dimmer switch. As a robot gets closer to a wall, it might gradually slow down rather than stopping suddenly when it reaches a specific distance. This creates smoother, more natural-looking movements but requires more complex programming.</p>
<p>&nbsp;</p>

<p>For example, a robot might adjust its speed based on how close it is to an obstacle:</p>
<ul>
<li>When far away (more than 50cm): move at full speed</li>
</ul>
<ul>
<li>When getting closer (20-50cm): slow down proportionally</li>
</ul>
<ul>
<li>When very close (less than 20cm): stop completely</li>
</ul>
<p>&nbsp;</p>

<p>This gradual response makes the robot's movements appear more fluid and natural.</p>
<p>&nbsp;</p>

<p>
        <figure class="table" style="float:left;width:92.41%;" data-font-size="14" data-line-height="20">
            <table class="ck-table-resized" style="border-style:none;" data-font-size="14" data-line-height="20">
                <colgroup data-font-size="14" data-line-height="20"><col style="width:13.29%;" data-font-size="14" data-line-height="20"><col style="width:86.71%;" data-font-size="14" data-line-height="20"></colgroup>
                <tbody data-font-size="14" data-line-height="20">
                    <tr data-font-size="14" data-line-height="20">
                        <td style="border-style:none;" data-font-size="14" data-line-height="20">
                            <figure class="image image_resized" style="width:100%;" data-font-size="14" data-line-height="20">
                                <img style="aspect-ratio:600/600;" src="https://api.learnstage.com/media-manager/api/access/exceled/default/89309a11-e6ae-4133-97a9-93c735f38be4/content-page/4e85aa67-83db-423a-b7de-53b356164071_removalai_preview.png" width="600" height="600" data-font-size="14" data-line-height="20">
                            </figure>
                        </td>
                        <td style="border-style:none;" data-font-size="14" data-line-height="20">
                            <h3 data-font-size="16" data-line-height="23">
                                <span style="color:hsl(359,97%,29%);"><span data-font-size="16" data-line-height="23"><strong data-font-size="16" data-line-height="23">Key Takeaways</strong></span></span>
                            </h3>
                            <ul>
<li>Sensors act like a robot's eyes and ears, collecting information from the environment that helps the robot make decisions about what to do next.</li>
<li>Robots follow an input-processing-output (IPO) pattern: they take in sensor data, think about what it means, and then respond with actions like moving or making sounds.</li>
<li>Robot programs can respond to sensors in different waysâ€”either by making yes/no decisions at specific thresholds or by making smooth, gradual adjustments as sensor readings change.</li>
</ul>
                        </td>
                    </tr>
                </tbody>
            </table>
        </figure></p>
<p>&nbsp;</p>
    </div>
    