# 9.4
# **Ethical Decision-Making in Robot Design**
## **Learning Objectives**
By the end of this session, you'll be able to:
- Apply simple ethical frameworks to evaluate robot design decisions
- Identify different stakeholders affected by robot implementation
- Design robot features that accommodate users with diverse needs and abilities

### **Lesson Podcast Discussion: Stakeholder Perspectives in Robotics**
This podcast explores the various stakeholders impacted by robot implementation and how to balance their potentially conflicting interests.

## **Ethical Frameworks for Decision-Making**
When designing robots, we need tools to help us make good choices. **Ethical frameworks** are like special thinking tools that help us consider what's right and fair when creating new technology. These frameworks can guide us to make better decisions about how robots should work and interact with people.

### **Balancing Benefits and Harms**
When designing robots, it's important to think about both the good and bad effects they might have. For example, a delivery robot might help people get packages faster (a benefit), but it could also take away jobs from human delivery workers (a potential harm).

Good robot designers create a list of all possible benefits and harms. They ask questions like: "Who will this robot help?" and "Could this robot cause problems for anyone?" They try to design robots that maximize benefits while minimizing harms.

For example, when designing a robot vacuum, engineers might make sure it cleans effectively (benefit) while adding sensors to prevent it from bumping into pets or falling down stairs (reducing harm).

**Real-world example:** The designers of helper robots for people with disabilities carefully balance benefits and harms. The Obi feeding robot helps people who cannot feed themselves independently, providing dignity and independence (benefits). However, designers had to carefully consider potential harms like safety concerns if the robot moved too quickly or privacy issues if it collected too much data about eating habits. They addressed these concerns by adding emergency stop buttons, creating simple controls, and limiting unnecessary data collection.

### **Considering Rights and Fairness**
Everyone has certain rights that should be respected, even when interacting with robots. These include privacy, safety, and being treated fairly. When designing robots, we need to think about how to protect these rights.

For instance, a robot that takes photos in public spaces should be designed to protect people's privacy. Maybe it blurs faces automatically or asks for permission before recording. 

**Fairness** means the robot works well for everyone, not just certain groups. If a robot receptionist only recognizes certain accents or skin tones, it's not treating everyone fairly. Good robot design ensures that robots work equally well for all types of people.

### **Thinking About Consequences**
Robot designers need to think about what might happen after their robot is being used - both right away and in the future. This is called "**consequential thinking**."

Short-term consequences might include how people first react to the robot or immediate safety concerns. Long-term consequences could involve how the robot might change jobs, social interactions, or the environment over time.

For example, when designing educational robots for classrooms, designers should consider: "Will students become too dependent on robots for answers?" or "How might this change the role of teachers in the future?" By thinking ahead, we can design robots that have positive long-term effects.

---pagebreak---

## **Activity 1: Stakeholder Analysis Workshop**
Identify all people affected by a specific robot scenario. Create a chart listing each stakeholder (e.g., users, businesses, maintenance staff, bystanders) and how their needs might differ or conflict. Consider how you would prioritize these different needs when finalizing your design decisions.

## **Stakeholder Analysis in Robot Design**
When we create robots, many different people will be affected by them. Understanding who these people are and what they need helps us make better design choices.

### **Identifying Who Is Affected**
**Stakeholders** are all the people who might interact with or be affected by a robot. They include:

- **Direct users**: People who will operate or work directly with the robot
- **Indirect users**: People who benefit from the robot's work but don't control it
- **Bystanders**: People who might encounter the robot but aren't using it
- **Maintenance workers**: People who repair and maintain the robot
- **Businesses or organizations**: Groups that own or sell the robot
- **Community members**: People living where the robot operates

For example, a hospital delivery robot's stakeholders include nurses who program it, patients who receive medications from it, visitors who pass it in hallways, technicians who fix it, the hospital administration that purchased it, and even janitorial staff who clean around it.

Making a complete list of stakeholders is the first step in ethical robot design. This helps make sure we don't accidentally ignore important groups of people.

### **Understanding Different Needs**
Different stakeholders often have very different needs and concerns about robots. What works well for one group might create problems for another.

For example, with a school security robot:
- School administrators might want constant monitoring and facial recognition
- Students might be concerned about privacy and feeling watched
- Parents might want safety but worry about data collection
- Maintenance staff need the robot to be easy to repair
- Visitors need clear information about where the robot is and what it does

Good robot designers take time to talk with different stakeholders and understand their unique perspectives. They might use surveys, interviews, or focus groups to learn what each group needs and values.

**Stakeholder engagement example:** When designing a robot to help in school libraries, one company invited students, teachers, librarians, and school administrators to participate in design workshops. They used simple activities like drawing their "dream library robot" and sorting feature cards by importance. The company discovered that while librarians wanted help shelving books, students most wanted help finding books on topics they were interested in. This led to a robot design with both shelving capabilities and an interactive screen where students could search for book recommendations.

---stopandreflect---
## Stop and reflect

**CHECKPOINT:** Think about a robot designed for use in schools. Who are all the different people who might interact with or be affected by this robot? Consider how the needs of students, teachers, administrators, custodial staff, and parents might differ.
---stopandreflectEND---

### **Resolving Conflicting Interests**
Sometimes different stakeholders want things that conflict with each other. For example, users might want a robot that works very quickly, while bystanders want one that moves slowly for safety.

When interests conflict, robot designers can use several strategies:

1. **Find creative compromises**: Design features that meet multiple needs at once. For example, a robot could move quickly in empty areas but slow down when people are nearby.

2. **Prioritize based on values**: Decide which values matter most, like safety, efficiency, or accessibility. This helps determine which needs should come first.

3. **Include adjustable settings**: Create robots that can be customized for different situations or users.

4. **Involve stakeholders in decisions**: Bring different groups together to discuss trade-offs and find solutions everyone can accept.

For example, when designing a restaurant serving robot, designers might prioritize food safety first, then create adjustable speed settings that restaurant managers can change during busy or quiet times.

---pagebreak---

## **Inclusive and Accessible Design**
Creating robots that everyone can use, regardless of their abilities or background, is both ethical and practical. **Inclusive design** makes robots more useful for all people.

### **Designing for Different Abilities**
People have different physical and cognitive abilities. Some people have limited vision, hearing, mobility, or cognitive processing. Good robot design takes these differences into account.

For example, a robot might include:
- Voice commands for people who can't use touch screens
- Visual signals for people who can't hear audio alerts
- Simple, clear instructions for people with cognitive disabilities
- Physical designs that don't require fine motor control
- Height adjustments for people in wheelchairs or of different statures

The best approach is called "**universal design**" - creating robots that work well for as many people as possible without needing special adaptations. For instance, a robot with both voice and screen interfaces works for people who can see, people who can hear, and people who can do both.

**Real-world example:** Robots that help people with disabilities show how inclusive design works in practice. One robot designed to help people with mobility impairments was created with adjustable height controls, multiple ways to give commands (voice, touch screen, and physical buttons), and simple, clear instructions with pictures. The designers tested the robot with people who use wheelchairs, people with limited hand strength, and people with different cognitive abilities to make sure everyone could use it successfully.

### **Cultural and Social Inclusivity**
Robots should work well for people from all cultural backgrounds and social situations. This means considering differences in:

- Languages spoken
- Cultural gestures and customs
- Economic resources
- Technical experience and comfort with technology
- Living environments (urban, rural, etc.)

For example, a robot designed for international use should speak multiple languages and avoid gestures that might be offensive in some cultures. A robot for public spaces should be usable by people with limited technology experience and not require expensive smartphones to interact with it.

Inclusive design also means considering how robots might affect different communities. Will the robot be affordable for schools in all neighborhoods? Does it require high-speed internet that some areas don't have?

**Global perspectives:** Attitudes toward robots vary greatly around the world. In Japan, robots are often welcomed as helpers and even companions. In some parts of Europe, people may be more concerned about robots replacing jobs. In many African countries, there's growing interest in how robots can help with healthcare and education where there aren't enough human workers. In some indigenous communities, there are important questions about how robots might affect traditional ways of life and cultural practices. Good robot designers learn about these different perspectives and create robots that respect local values and needs.

### **Testing with Diverse Users**
The best way to ensure robots work for everyone is to test them with diverse groups of users. This means including people of different:

- Ages
- Abilities
- Cultural backgrounds
- Technology experience levels
- Genders

When testing, designers should observe how different people interact with the robot and listen to their feedback. Often, users will identify problems that designers never considered.

For example, a company designing a robot museum guide might test it with elderly visitors, children, international tourists, and people with various disabilities. Each group will provide valuable insights about how to improve the robot's design.

Testing should happen early and often throughout the design process, not just at the end. This way, problems can be fixed before the robot is finalized.

## **Activity 2: Inclusive Design Challenge**
Select an existing robot design (e.g., a customer service robot or educational robot) and modify it to make it more accessible for users with a specific disability. Consider what features you would add or change to ensure the robot could be effectively used by someone with a visual, hearing, or mobility impairment.

---stopandreflect---
## Stop and reflect

**CHECKPOINT:** Have you ever encountered a technology that was difficult for you to use? Reflect on how it could have been better designed to meet your needs and consider how this experience might inform your approach to inclusive robot design.
---stopandreflectEND---

---checkyourunderstanding---
When designing a robot for a public library, which approach best demonstrates ethical decision-making?

A. Designing the robot to be as technologically advanced as possible

B. Making the robot look exactly like a human librarian

C. Ensuring the robot can complete tasks as quickly as possible

D. Considering the needs of users with different abilities, ages, and technological comfort levels
---answer---
The correct answer is D. Considering the needs of users with different abilities, ages, and technological comfort levels. Ethical decision-making in robot design involves considering the diverse needs of all potential users. A library serves people of varying ages, abilities, and comfort with technology, so the robot should be designed to be accessible and usable by everyone who might encounter it. If you chose a different answer, remember that technological advancement, human-like appearance, or speed are not necessarily ethical priorities if they don't serve the needs of diverse users.
---answerEND---
---checkyourunderstandingEND---

## **Key Takeaways**
- Ethical frameworks provide structured approaches to making design decisions about robots
- Robot design affects multiple stakeholders whose needs and interests should be considered
- Inclusive design ensures robots are accessible and useful to people with diverse abilities and backgrounds

[End of Lesson]

## Instructional designer notes of lesson 9.4
**This lesson fits into the the overall module of 9 in the following ways:**
- It provides practical tools for applying ethical principles to the robot design process
- It builds on theoretical foundations from earlier lessons in the ethics module
- It prepares students for the synthesis of ethical concepts in Lesson 5

**This lesson could be followed by this game:**
Design Dilemma Cards: Players are presented with robot design scenarios containing ethical challenges and must collaborate to develop solutions that address the needs of all stakeholders. For example, students might receive a card describing a delivery robot that must navigate crowded sidewalks, and they must identify the stakeholders affected and propose design features that balance efficiency, safety, and accessibility.

Additional Writer Notes:
I addressed the following SME feedback points:
1. Added concrete case studies showing ethical frameworks applied to commercial products (Obi feeding robot example)
2. Included a detailed example of stakeholder engagement methodology (library robot design workshop)
3. Added content on robots that help people with disabilities as an example of inclusive design
4. Expanded global cultural perspectives content beyond Western/Eastern comparisons to include African countries and indigenous communities
5. All examples were simplified to be appropriate for the 11-14 year old target audience