
    <div class="markdown-content" style="font-family: Arial, sans-serif; line-height: 1.6; color: #333; max-width: 800px; margin: 0 auto;">
        <h1>4.9</h1>

<h1>From Sensing to Action</h1>

<h2>Learning Objectives</h2><p>By the end of this session, you'll be able to:</p>
<ul>
<li>Explain how robots use sensors to "see" their world</li>
</ul>
<ul>
<li>Show how robots use rules to make choices based on sensor data</li>
</ul>
<ul>
<li>Give examples of how robots handle data from many sensors at once</li>
</ul>
<h3>Lesson Podcast Discussion: The Information Pathway in Robotics</h3><p>This podcast explores how information flows from sensor inputs through processing systems to trigger meaningful robot actions.</p>
<h2>The Information Pathway</h2>

<h3>Sensor Input Collection</h3><p>Robots use sensors as their "eyes and ears" to understand the world around them. Just like how your eyes detect light and your ears detect sound, robot sensors detect different types of physical information from the environment. For example, a light sensor detects brightness levels, a distance sensor measures how far away objects are, and a touch sensor detects when something makes contact with the robot.</p>
<p>&nbsp;</p>

<p>When a sensor detects something in the environment, it converts that physical information into electrical signals. Think of it like translating one language into another. A temperature sensor, for instance, converts heat levels into electrical signals that the robot can understand. These electrical signals are the "raw data" that flows into the robot's brain (its processor) for the next step in the pathway.</p>
<h3>Data Processing and Interpretation</h3><p>The robot then interprets this filtered data using programmed rules. For example, if a light sensor detects a value below 20, the robot might interpret this as "it's dark." If a distance sensor reports a value of 5 centimeters, the robot might interpret this as "there's an obstacle very close to me." This interpretation transforms raw numbers into meaningful information that the robot can use to make decisions.</p>
<p>&nbsp;</p>

<p>Some robots use special techniques to clean up messy sensor data. For instance, averaging multiple readings can help reduce errors, similar to how you might take the average of several test scores. Other robots use "threshold filtering" where they only respond when a sensor reading crosses a certain value - like only reacting to sounds louder than a whisper.</p>
<h3>Triggering Robot Responses</h3><p>The connection between sensor interpretation and robot action is defined by the robot's programming. Programmers create rules that tell the robot exactly what to do in response to specific sensor information. This final step completes the information pathway from sensing the environment to taking action in it.</p>
<h2>Decision-Making Based on Sensor Data</h2>

<h3>Simple If-Then Logic</h3><p><strong>If-then statements</strong> are the building blocks of robot decision-making. These simple logical rules tell the robot what to do when certain conditions are met. For example: "IF the temperature sensor reads above 30 degrees Celsius, THEN turn on the cooling fan." This type of logic creates a direct connection between what the robot senses and how it responds.</p>
<h3>Simple If-Then Logic</h3><p>Programmers often use <strong>if-then-else structures</strong> to cover all possible scenarios. The "else" part tells the robot what to do when the "if" condition isn't true. For example: "IF the distance sensor detects an object within 10 cm, THEN stop and turn right, ELSE continue moving forward." This ensures the robot always has a clear action to take, no matter what its sensors detect.</p>
<h3>Combining Multiple Sensor Inputs</h3><p>Real-world robots rarely rely on just one sensor to make decisions. Instead, they combine information from multiple sensors to get a more complete picture of their environment. For example, a robot vacuum might use a combination of bump sensors, cliff sensors, and camera sensors to navigate safely around your home.</p>
<p>&nbsp;</p>

<p>When working with multiple sensors, robots need ways to prioritize or combine the information. One approach is to use <strong>"AND" and "OR" logic</strong>. For example: "IF the light sensor detects darkness AND the motion sensor detects movement, THEN turn on the security light." This means both conditions must be true for the action to happen. With "OR" logic, only one condition needs to be true: "IF the smoke sensor detects smoke OR the temperature sensor reads above 100 degrees, THEN trigger the alarm."</p>
<h3>Combining Multiple Sensor Inputs</h3><p>In self-driving cars, this combination of sensors is critical for safety. These vehicles use cameras to see lane markings, radar to detect other vehicles, and ultrasonic sensors to measure close distances when parking. The car's computer combines all this information to make driving decisions, giving highest priority to avoiding collisions with people or objects.</p>
<p>&nbsp;</p>

<p>
            <div class="stop-reflect-container" style="border:3px dashed #e50200; margin:20px 0; padding:0; display:flex; width:100%;">
                <div class="stop-reflect-image" style="width:20%; min-width:100px; display:flex; align-items:center; justify-content:center; padding:10px;">
                    <img src="https://api.learnstage.com/media-manager/api/access/exceled/default/lms/courses/1647/Images/Untitled%20design.jpg" 
                         style="width:100%; height:auto; max-width:150px;" alt="Stop and Reflect">
                </div>
                <div class="stop-reflect-content" style="display:flex; flex-direction:column; justify-content:center; padding:15px; width:80%;">
                    <h3 style="color:#000000; margin-top:0;">
                    </h3><p> Think about a time when one of your senses gave you incorrect information, such as an optical illusion or misheard sound. How might similar sensory misinterpretations affect a robot's ability to function correctly in its environment?</p>
                </div>
            </div></p>
<h3>Prioritizing Conflicting Sensor Information</h3><p>Sometimes sensors provide contradictory information, and robots need strategies to resolve these conflicts. Imagine a robot with both a light sensor and a camera. The light sensor indicates it's dark, but the camera is still capturing clear images. Which sensor should the robot trust?</p>
<p>&nbsp;</p>

<p>One common approach is to establish a <strong>"sensor hierarchy"</strong> where certain sensors are trusted more than others in specific situations. For example, safety-related sensors like obstacle detectors might always take priority over other sensors. If the obstacle sensor says "stop" but the line-following sensor says "go forward," the robot will stop to avoid a collision.</p>
<h3>Prioritizing Conflicting Sensor Information</h3><p>Engineers design robots with <strong>backup systems</strong> so they can still function even if one sensor fails. For example, a delivery robot that normally uses cameras to navigate might switch to using sonar sensors if its cameras get covered in mud. This is like how you might use your sense of touch to find your way around a dark room when you can't see.</p>
<p>&nbsp;</p>

<p>
        <figure class="table" style="float:left;width:92.41%;" data-font-size="14" data-line-height="20">
            <table class="ck-table-resized" style="border-style:none;" data-font-size="14" data-line-height="20">
                <colgroup data-font-size="14" data-line-height="20"><col style="width:13.29%;" data-font-size="14" data-line-height="20"><col style="width:86.71%;" data-font-size="14" data-line-height="20"></colgroup>
                <tbody data-font-size="14" data-line-height="20">
                    <tr data-font-size="14" data-line-height="20">
                        <td style="border-style:none;" data-font-size="14" data-line-height="20">
                            <figure class="image image_resized" style="width:100%;" data-font-size="14" data-line-height="20">
                                <img style="aspect-ratio:600/600;" src="https://api.learnstage.com/media-manager/api/access/exceled/default/89309a11-e6ae-4133-97a9-93c735f38be4/content-page/4e85aa67-83db-423a-b7de-53b356164071_removalai_preview.png" width="600" height="600" data-font-size="14" data-line-height="20">
                            </figure>
                        </td>
                        <td style="border-style:none;" data-font-size="14" data-line-height="20">
                            <h3 data-font-size="16" data-line-height="23">
                                <span style="color:hsl(359,97%,29%);"><span data-font-size="16" data-line-height="23"><strong data-font-size="16" data-line-height="23">Key Takeaways</strong></span></span>
                            </h3>
                            <ul>
<li>Robots use sensors to collect information about their environment, which gets converted into electrical signals that the robot's processor can understand.</li>
<li>Robots make decisions using if-then logic, where specific sensor readings trigger programmed actions based on predefined rules.</li>
<li>Complex robot systems combine multiple sensors and use prioritization strategies to resolve conflicting information, ensuring more reliable operation.</li>
</ul>
                        </td>
                    </tr>
                </tbody>
            </table>
        </figure></p>
<p>&nbsp;</p>
    </div>
    