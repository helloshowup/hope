# 6.11
# **Connecting Sensors to Actions**

## Learning Objectives

By the end of this session, you'll be able to:
- Explain how sensors help robots "see" and "feel" their world
- Use the Input-Process-Output (IPO) model to plan robot actions
- Write simple code that makes robots respond to sensors

### **Lesson Podcast Discussion: How Sensors Enable Autonomous Robot Behavior**

This podcast explores how properly programmed sensors transform robots from pre-programmed machines into responsive, adaptive systems capable of making decisions based on their environment.

## **Sensor Inputs in Programming**

Robot sensors are the "eyes and ears" that allow machines to perceive their environment. In programming terms, sensors provide the critical input data that robots need to make decisions. Understanding how to incorporate sensor data into your programs is essential for creating responsive, intelligent robots.

### **Types of Sensor Inputs in Code**

Different sensors provide different types of data that your program needs to handle:
- **Binary sensors** (like touch sensors) provide simple on/off or true/false values
- **Analog sensors** (like light or distance sensors) provide a range of numerical values
- **Complex sensors** (like cameras) provide structured data requiring more sophisticated processing

When programming with sensors, you'll need to access their values through specific functions or methods. For example:
```python
if touch_sensor.is_pressed():
    robot.move_backward()
    
distance = ultrasonic_sensor.get_distance()
if distance < 20:
    robot.turn_left()
```


## **The Input-Processing-Output Framework**

The **IPO (Input-Processing-Output)** framework is fundamental to understanding how sensors connect to robot actions:

1. **Input**: Sensors collect data from the environment
2. **Processing**: Your program analyzes the sensor data and makes decisions
3. **Output**: The robot executes actions based on those decisions

### **Decision Structures for Sensor Processing**

The most common programming structures for handling sensor inputs are:

- **If-else statements**: Make simple decisions based on sensor readings
```python
if light_sensor.get_value() < 50:
    robot.turn_on_lights()
else:
    robot.turn_off_lights()
```

- **Loops with conditionals**: Continuously monitor sensors and respond
```python
while True:
    if distance_sensor.get_value() < 10:
        robot.stop()
    else:
        robot.move_forward()
```

- **Functions**: Encapsulate sensor-response behavior
```python
def avoid_obstacle():
    robot.stop()
    robot.turn_right(90)
    robot.move_forward(2)
```

## **Creating Sensor Response Programs**

Now let's look at how to create complete programs that use sensors to drive robot behavior.

### **Basic Sensor Response Pattern**

Most sensor-based programs follow this basic pattern:

1. Initialize the robot and sensors
2. Enter a continuous loop that:
   - Reads sensor values
   - Processes the values using conditionals
   - Executes appropriate actions
3. Clean up resources when done

Here's a simple example of a light-following robot:

```python
# Initialize
robot = Robot()
light_sensor = LightSensor(port=1)

# Main loop
while not robot.button.is_pressed():
    light_value = light_sensor.get_value()
    
    if light_value > 70:  # Bright light detected
        robot.move_forward()
    elif light_value > 30:  # Medium light
        robot.turn_toward_light()
    else:  # Low light
        robot.stop()
        
# Cleanup
robot.close()
```

## **Activity 1: Program a Robot to Respond to a Touch Sensor**

In this activity, you'll create a simple program for a virtual robot that uses a touch sensor to detect obstacles. Open the virtual robot simulator in a new tab and write a program that:
1. Makes the robot move forward continuously
2. Detects when the touch sensor is pressed (indicating an obstacle)
3. Makes the robot back up, turn 90 degrees right, and continue moving forward
4. Test your program with various obstacle configurations to see how well it works

## **Testing Sensor-Based Programs**

Sensor-based programs require thorough testing because they interact with the physical world, which can be unpredictable.

### **Systematic Testing Approaches**

When testing sensor programs:

1. **Test individual sensor readings**: Verify that your program correctly reads the sensor values
2. **Test thresholds and boundaries**: Check if your program responds correctly at the edge of decision thresholds
3. **Test response actions**: Ensure the robot performs the expected actions when sensor conditions are met
4. **Test in different environments**: Try your program under different lighting conditions, surfaces, or obstacle arrangements

### **Debugging Sensor Programs**

Common issues in sensor programming include:

- **Incorrect thresholds**: Your sensor values may need calibration for different environments
- **Timing issues**: Sensor readings might be too fast or too slow for effective decision-making
- **Conflicting sensor inputs**: Multiple sensors might suggest contradictory actions

---stopandreflect---
## Stop and reflect

**CHECKPOINT:** Consider a robot that navigates through a room without bumping into walls or objects. What sensors would it need, and how would you connect those sensors to movement decisions in your code?
---stopandreflectEND---
---keytakeaways---
## Key Takeaways
- Sensors act as a robot's "eyes and ears," collecting environmental data that allows robots to make decisions and respond to their surroundings.
- The Input-Processing-Output (IPO) framework guides robot programming: sensors gather data (input), your code analyzes it (processing), and the robot performs actions (output).
- Effective sensor programming uses decision structures like if-else statements and loops to continuously monitor sensor values and trigger appropriate robot responses.
---keytakeawaysEND---




