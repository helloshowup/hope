# 10.4

# Connecting to What We Learned

## Learning Objectives

By the end of this session, you'll be able to:
- Explain how robots use input, process, and output to work
- Name at least 3 types of sensors and 3 types of motors used in robots
- Show how loops and if-then logic help robots make choices

### Input-Processing-Output in Advanced Robots

Remember the input-processing-output model we learned about in Module 1? This fundamental concept remains at the heart of even the most advanced robots being developed today, though the technologies used for each stage have become incredibly sophisticated.

For **input**, next-generation robots use sensors that far exceed human capabilities. Some robots can now "see" using multiple types of vision simultaneously - regular cameras, infrared sensors that detect heat, and even LIDAR systems that use laser beams to create detailed 3D maps of the environment. Touch sensors have evolved from simple pressure switches to artificial skin that can detect texture, temperature, and even wetness. Some robots can even "smell" using chemical sensors that detect specific molecules in the air, allowing them to identify gas leaks or spoiled food.

The **processing** systems in advanced robots have made enormous leaps forward. While basic robots might use simple if-then logic like we practiced in Module 4, today's cutting-edge robots use powerful computers running complex AI algorithms. These systems can process massive amounts of sensor data in real-time, recognize patterns, and even predict what might happen next. For example, a delivery robot doesn't just detect obstacles - it can predict which way a person might move based on their body language and adjust its path accordingly.

**Output** mechanisms have also evolved dramatically. Beyond basic wheels and grippers we explored in Module 3, advanced robots now use artificial muscles that contract like human muscles, micro-motors that can make extremely precise movements, and even shape-changing materials that transform in response to electrical signals. Some robots can now perform tasks requiring extraordinary dexterity, like threading a needle or decorating a cake with intricate patterns. Others use advanced communication outputs, generating natural-sounding speech or displaying expressions on screen faces to interact more naturally with humans.

Digital thermometers are a great example of the input-processing-output model in everyday technology. These simple medical devices use a temperature sensor (input) to detect body heat, a tiny computer chip (processing) to convert the sensor reading into a temperature measurement, and a digital display (output) to show the temperature. More advanced versions can even store readings over time or connect to smartphones to track health patterns.

Blood pressure monitors work similarly, using a pressure sensor (input) to detect the pressure in an inflated cuff, processing circuits to analyze the pressure changes as blood flows through your arm, and a display (output) that shows your systolic and diastolic readings. These devices help people monitor their health at home without needing to visit a doctor for every measurement.

### Movement Principles in Next-Gen Robots

The basic principles of robot movement we studied in Module 3 still apply to next-generation robots, but engineers are finding incredible new ways to implement these principles. Traditional wheels and tracks are being reimagined with omnidirectional designs that can move in any direction without turning, perfect for navigating crowded spaces like hospitals or warehouses.

Legged locomotion has seen particularly exciting advances. While early walking robots were slow and unstable, today's legged robots can run, jump, and even do backflips! By using principles from animal movement and advanced balance systems, robots like Boston Dynamics' Atlas can recover from pushes and navigate uneven terrain that would stop wheeled robots completely. Some robots combine multiple movement types - transforming from a wheeled configuration to a legged one when they encounter stairs, for example.

For manipulation (how robots grab and handle objects), we're seeing a revolution in gripper design. Traditional pincer-like grippers work well for uniform objects but struggle with irregular shapes. New designs include soft grippers that conform around objects like a balloon filled with coffee grounds that becomes rigid when air is removed, and gecko-inspired adhesive pads that can pick up objects without squeezing them at all. Some of the most advanced robot hands have multiple jointed fingers with dozens of sensors, allowing them to handle delicate objects like eggs or lightbulbs without breaking them.

These movement innovations are making robots useful in many new environments - from search and rescue operations in disaster zones to assisting elderly people in their homes, where adaptability to different surfaces and gentle, precise movements are essential.

### Programming Concepts in Future Systems

Programming approaches for robots are evolving rapidly to handle increasingly complex capabilities. Traditional programming, where developers write specific instructions for every situation a robot might encounter, is becoming less practical as robots work in more unpredictable environments. Instead, modern robotics often uses a combination of programming methods.

**Behavior-based programming** creates layers of simple behaviors that work together to produce complex actions. For example, a robot might have separate behaviors for "avoid obstacles," "move toward goal," and "maintain balance." These behaviors run simultaneously, with a priority system determining which one takes control in different situations. This approach helps robots respond quickly to changing conditions without needing to analyze every possible scenario in advance.

**Machine learning** approaches are increasingly important, allowing robots to improve their performance through experience. Rather than programming exactly how to grasp an object, engineers might create a learning system where the robot tries different approaches and gradually improves based on success or failure. This is particularly valuable for tasks that are difficult to define precisely, like recognizing speech in noisy environments or predicting human behavior.

**Visual programming tools** are making robotics more accessible, allowing people without traditional coding experience to program robots using graphical interfaces. These tools use blocks or flowcharts to represent actions and decisions, similar to the block-based programming we practiced in Module 5, making it easier to understand the robot's logic. Some advanced systems even allow programming by demonstration - a person physically guides the robot through a task, and the robot learns to repeat it.

The sequences, loops, and conditionals we learned in Module 5 are still the building blocks of these advanced programming approaches. For instance, a self-driving car uses conditionals (IF there's an obstacle, THEN slow down) and loops (WHILE driving, continuously check sensors) just like our simpler robots, but with much more complex conditions and actions.

As robots become more integrated into our daily lives, these programming approaches will continue to evolve, making robots more adaptable, easier to work with, and capable of learning new tasks without requiring complete reprogramming.

---stopandreflect---
**CHECKPOINT:** How do the robots of today compare to what you imagined robots would be like before taking this course?
---stopandreflectEND---

### The Input-Processing-Output Framework

Robots interact with the world in three main steps, forming what we call the input-processing-output framework. 

First, robots gather information through **input devices** like sensors. These are like the robot's "senses" - similar to how we use our eyes, ears, and sense of touch to understand our surroundings. For example, a robot might use a distance sensor to detect obstacles or a light sensor to follow a line on the floor.

Next comes **processing**, where the robot's "brain" (usually a microcontroller or computer) makes decisions based on the input information. This is where programming comes in! The code we write tells the robot what to do with the information it receives. For instance, if a distance sensor detects an obstacle is too close, the processing unit might decide the robot needs to turn to avoid a collision.

Finally, the robot takes action through **output devices** like motors, speakers, or lights. These components allow the robot to move, make sounds, or display information. When our code decides the robot should turn to avoid an obstacle, motors activate to change the robot's direction.

This framework helps us understand and design any robot, from simple line followers to complex humanoid robots. Every robot follows this same basic pattern!

Let's look at a real-world example: a digital thermometer you might use when you're sick. It takes input (your body temperature) through its sensor tip, processes that reading with its tiny computer chip, and produces output by displaying the temperature on its screen. Simple medical devices like this follow the same input-processing-output pattern as complex robots!

### Types of Sensors and Actuators

Throughout our course, we've explored many ways robots can sense and interact with their environment.

**Sensors** are the input devices that collect information. We've worked with:
- Light sensors that detect brightness levels
- Distance sensors that measure how far away objects are
- Touch sensors that detect physical contact
- Color sensors that can identify different colors
- Sound sensors that detect noise levels
- Temperature sensors that measure heat

**Actuators** are the output devices that allow robots to take action. The main types we've used include:
- DC motors that spin wheels for movement
- Servo motors that can move to precise positions
- LED lights that provide visual feedback
- Speakers that produce sounds
- LCD displays that show text and numbers

Each sensor and actuator has specific uses in robotics. For example, a rescue robot might use distance sensors to navigate through rubble, temperature sensors to detect survivors, and motors to move toward people who need help. Understanding which sensors and actuators to use for different situations is a key skill in robotics design!

### Power Systems and Structural Elements

Every robot needs energy to operate and a physical structure to support its components.

For **power systems**, we've explored several options:
- Batteries are the most common power source for mobile robots. They're portable but have limited energy storage.
- Wall adapters provide continuous power but limit mobility since the robot must stay plugged in.
- Solar panels can generate electricity from light, making them useful for outdoor robots that need to operate for long periods.

The right power source depends on your robot's needs. A small line-following robot might work fine with AA batteries, while a larger robot arm might need a more powerful battery pack or wall adapter.

When choosing batteries for your project, consider:
- Battery life: How long will your robot need to run between charges?
- Weight: Heavier batteries provide more power but make your robot harder to move
- Size: Will the batteries fit in your robot's design?
- Rechargeability: Rechargeable batteries cost more initially but save money over time

For **structural elements**, we've learned about:
- Chassis designs that form the robot's body and hold components in place
- Wheels, tracks, and legs that provide different movement capabilities
- Mounting brackets that secure motors, sensors, and other parts
- Materials like plastic, metal, and wood that offer different combinations of weight, strength, and cost

Good structural design ensures your robot is sturdy enough to perform its tasks without breaking. For example, a robot designed to pick up heavy objects needs stronger materials and more secure mounting points than a lightweight drawing robot.

When selecting structural materials, consider:
- Strength: Can the material support all components without bending or breaking?
- Weight: Lighter materials make your robot more efficient but might be less durable
- Ease of working: Can you cut and connect the material with the tools you have?
- Cost: More expensive materials might perform better but limit what you can build

### Sequences, Loops, and Conditionals

Programming robots requires understanding three fundamental structures that control how code runs.

**Sequences** are the simplest structure - they're just a series of commands that run one after another. Like a recipe that says "first add flour, then add eggs, then mix," a sequence in robotics might be "move forward, turn right, move forward again." The robot follows these steps in order, from first to last. We use sequences when we want our robot to perform a specific series of actions in a fixed order.

**Loops** allow us to repeat actions without writing the same code over and over. There are two main types we've used:
- Count-controlled loops (like "repeat 5 times") that run a specific number of times
- Condition-controlled loops (like "repeat until sensor detects an obstacle") that run until something specific happens

Loops are super useful for tasks like having a robot patrol an area by moving in a square pattern over and over, or continuously checking a sensor for changes.

**Conditionals** let our robots make decisions using "if-then-else" logic. For example: "IF the distance sensor reads less than 10cm, THEN turn right, ELSE keep moving forward." Conditionals are what give robots the ability to respond differently based on what their sensors detect. They're essential for creating robots that can adapt to their environment rather than just blindly following instructions.

By combining sequences, loops, and conditionals, we can create sophisticated robot behaviors that respond intelligently to the world around them!

### Variables and Functions

Variables and functions are powerful tools that make our robot programs more flexible and organized.

**Variables** are like labeled containers that store information our program needs to remember. For example, we might create a variable called "distanceToWall" that holds the latest reading from a distance sensor. Variables can store numbers (like sensor readings), text (like messages to display), or true/false values (like whether a button is pressed). Using variables allows our robots to remember information and use it later in the program.

**Functions** are reusable blocks of code that perform specific tasks. Think of them as mini-programs within our main program. For example, we might create a function called "turnRight90Degrees" that contains all the code needed to make our robot turn exactly 90 degrees to the right. Then, whenever we want the robot to turn right, we can simply call this function instead of rewriting all the turning code.

Functions have several big advantages:
- They make our code cleaner and easier to read
- They let us reuse code without copying and pasting
- They help us break down complex problems into smaller, manageable pieces

For example, a line-following robot might have separate functions for "detectLine," "turnTowardLine," and "moveForward." By organizing our code this way, we can focus on getting each function working correctly, then combine them to create the complete line-following behavior.

### Algorithm Development

An **algorithm** is simply a step-by-step procedure for solving a problem or accomplishing a task. In robotics, we develop algorithms to help our robots achieve specific goals.

The process of developing an algorithm typically follows these steps:
1. Clearly define the problem or goal (e.g., "navigate through a maze")
2. Break the problem down into smaller sub-problems (e.g., "detect walls," "make turning decisions," "track position")
3. Design solutions for each sub-problem
4. Combine these solutions into a complete algorithm
5. Test and refine the algorithm until it works reliably

Throughout the course, we've used different approaches to develop algorithms:
- Flowcharts that visually map out decision paths
- Pseudocode that outlines logic in plain language before writing actual code
- Incremental development where we start with a simple version and gradually add features

For example, when developing an algorithm for a robot to follow a line, we might start with basic logic: "If the sensor sees the line, go forward. If the sensor doesn't see the line, turn until it finds the line again." Through testing, we might discover this makes the robot zigzag too much, so we refine the algorithm to make smoother adjustments based on how far the robot is from the center of the line.

Good algorithm development is about finding the right balance between simplicity (making the code easy to understand) and effectiveness (making the robot perform well).

---stopandreflect---
**CHECKPOINT:** Think about which programming concept you found most challenging during the course, and which you felt most comfortable with. How might these insights inform the type of final project you select?
---stopandreflectEND---


---keytakeaways---
## Key Takeaways
- Robots operate using the input-processing-output framework, where sensors gather information, a computer brain processes it, and actuators (like motors) take action based on programmed instructions.
- Effective robot design requires selecting appropriate sensors, actuators, power systems, and structural materials based on the robot's specific purpose and operating environment.
- Programming robots relies on three fundamental structures: sequences (ordered steps), loops (repeated actions), and conditionals (decision-making logic) that work together to create responsive robot behaviors.
---keytakeawaysEND---